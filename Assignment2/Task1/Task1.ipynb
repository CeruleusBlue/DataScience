{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below:</h5>\n",
    "    <ul>\n",
    "        <li>Reads the names and the discrete or continuous nature of the features </li>\n",
    "        <br>\n",
    "        <li>Reads the data and loads the data into dataframe</li>\n",
    "        <br>\n",
    "        <li>Maps the type of connection except normal to its corresponding attack class</li>\n",
    "        <br>\n",
    "        <li>\n",
    "            Drops the features which has only one value for all rows in the dataset\n",
    "            <br>\n",
    "            <i>\n",
    "                Note: This has been done because these features wouldn't be able to classify the data\n",
    "                in any way.\n",
    "            </i>\n",
    "        </li>\n",
    "    </ul>\n",
    "</spaN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "TARGETCOLUMN = 'connection_type'\n",
    "\n",
    "names = pd.read_table('Task1/kddcup.names', names=['col1','col2'], skiprows=[0], sep=': ', engine='python')\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'Task1/kddcup.data_10_percent_corrected', \n",
    "    names=pd.concat([names['col1'], pd.Series(TARGETCOLUMN)], ignore_index=True)\n",
    "    )\n",
    "\n",
    "# 0 : Symbolic\n",
    "# 1 : COntinuous\n",
    "columnValueType = [[],[]]\n",
    "def getColumnType(x):\n",
    "    if x['col2']=='symbolic.':\n",
    "        columnValueType[0].append(x['col1'])\n",
    "    else:\n",
    "        columnValueType[1].append(x['col1'])   \n",
    "\n",
    "names.apply(getColumnType, axis=1)\n",
    "\n",
    "del names\n",
    "\n",
    "attackclasses = {\n",
    "    'DOS':['back', 'land', 'neptune','pod','smurf','teardrop'],\n",
    "    'R2L':['ftp_write', 'guess_passwd', 'imap', 'multihop','phf','spy','warezclient','warezmaster'],\n",
    "    'U2R':['buffer_overflow', 'loadmodule', 'perl', 'rootkit'],\n",
    "    'Probe':['ipsweep','nmap','portsweep','satan']\n",
    "}\n",
    "\n",
    "def type_to_class(x:str)->str:\n",
    "    x = x[0:len(x)-1]\n",
    "    for i in attackclasses:\n",
    "        if x in attackclasses[i]:\n",
    "            return i\n",
    "    return x\n",
    "df[TARGETCOLUMN] = df[TARGETCOLUMN].apply(type_to_class)\n",
    "\n",
    "del attackclasses\n",
    "columns = []\n",
    "for i in df.columns:\n",
    "    if len(df[i].unique())==1:\n",
    "        columns.append(i)\n",
    "        if(i in columnValueType[0]):\n",
    "            columnValueType[0].remove(i)\n",
    "        else:\n",
    "            columnValueType[1].remove(i)\n",
    "df = df.drop(columns=columns)\n",
    "\n",
    "del columns, i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below:</h5>\n",
    "    <span>\n",
    "        Separates the data into train and test. This has been done by sampling rows of\n",
    "        each target column with a train test split of 7:3.\n",
    "    </span>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         normal\n",
       "2         normal\n",
       "9         normal\n",
       "16        normal\n",
       "17        normal\n",
       "           ...  \n",
       "494011    normal\n",
       "494014    normal\n",
       "494015    normal\n",
       "494018    normal\n",
       "494019    normal\n",
       "Name: connection_type, Length: 148209, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = pd.DataFrame()\n",
    "\n",
    "for i in  df[TARGETCOLUMN].unique():\n",
    "    subset = df[df[TARGETCOLUMN]==i]\n",
    "    train_x = pd.concat([train_x,subset.sample(int(0.7*len(subset))).drop(columns=[TARGETCOLUMN])])\n",
    "del subset, i\n",
    "train_y = df[TARGETCOLUMN].loc[train_x.index]\n",
    "test_x= df.loc[:,df.columns!=TARGETCOLUMN].loc[~df.index.isin(train_x.index)]\n",
    "test_y = df[TARGETCOLUMN].loc[test_x.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below:</h5>\n",
    "    <span style='font-weight:700'>Creates the Naive Bayes model class</span>\n",
    "    <ul>\n",
    "        <li>The object of the class must be created with the unique values of the target data as arguments</li>\n",
    "        <br>\n",
    "        <li>The gaussian function takes the value and distribution as parameters and returns the log of the gaussian probability</li>\n",
    "        <br>\n",
    "        <li>\n",
    "            The laplace function takes the frequency of the feature for in the subset containing only one target class value,\n",
    "            the length of the aforementioned subset, the number of categorical features and the smoothing alpha as parameters.\n",
    "            It then returns a smooth probability value.\n",
    "        </li>\n",
    "        <br>\n",
    "        <li>\n",
    "            The fit function:\n",
    "            <ol>\n",
    "                <li>Accepts the train features and target as parameters</li>\n",
    "                <li>Iterates for each class present in the target data</li>\n",
    "                <li>\n",
    "                    For each iteration:\n",
    "                    <ol>\n",
    "                        <li>Creates a subset of train features with only rows which contain a specific target class</li>\n",
    "                        <li>Stores probability of the occurence of the target class and the length of the target class</li>    \n",
    "                        <li>Iterates each column of the subset</li>\n",
    "                        <li>If the nature of the column values is continuous, stores the normal distribution of the column values</li>\n",
    "                        <li>If the nature of the column values is discrete, stores the probability of the occurence of each distinct column value</li>\n",
    "                    </ol>\n",
    "                </li>\n",
    "                <li>Returns a Naive Bayes object which has been fitted with train data</li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <br>\n",
    "        <li>\n",
    "            The predict function:\n",
    "            <ol>\n",
    "                <li>Stores the priors for each target class</li>\n",
    "                <li>Calls the rowPredictor function for each row of the test dataset</li>\n",
    "                <li>\n",
    "                    The rowPredictor function, calls the columnPredictor function passing along a dictionary \n",
    "                    of the probabilities of each target class for each column.\n",
    "                    <br> \n",
    "                    The dictionary of probabilities already contains the priors\n",
    "                    <br> \n",
    "                    It then returns dictionary of probabilities.\n",
    "                </li>\n",
    "                <li>\n",
    "                    The column predictor function, iterates through each target class.\n",
    "                    <br>\n",
    "                    If the column is discrete, the log of the laplace smoothened probability is added to the dictionary.\n",
    "                    <br>\n",
    "                    If the column is continuous, the gaussian probability is added to the dictionary.  \n",
    "                </li>\n",
    "                <li>The dictionary of probabilities for each row is returned as a Pandas series for the predict function</li>\n",
    "            </ol>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <span style='font-weight:700'>Creates a Naive Bayes object, fits the training data, and predicts the target class values for the test data</span >\n",
    "</span>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         {'normal': -7.640525424546775, 'U2R': -22.5071...\n",
       "2         {'normal': -8.132483750685834, 'U2R': -22.8953...\n",
       "9         {'normal': -9.065408863972142, 'U2R': -19.1331...\n",
       "16        {'normal': -11.897675880110306, 'U2R': -18.821...\n",
       "17        {'normal': -12.791466245678883, 'U2R': -19.446...\n",
       "                                ...                        \n",
       "494011    {'normal': -12.783593698624781, 'U2R': -19.411...\n",
       "494014    {'normal': -12.977825048731841, 'U2R': -19.681...\n",
       "494015    {'normal': -13.733744926312813, 'U2R': -20.700...\n",
       "494018    {'normal': -19.15888897344578, 'U2R': -19.4423...\n",
       "494019    {'normal': -13.55357900906668, 'U2R': -19.9178...\n",
       "Length: 148209, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NaiveBayes:\n",
    "    targetClasses = None\n",
    "    def __init__(self, targetClasses) -> None:\n",
    "        self.targetClasses = dict(zip(targetClasses, [dict() for x in targetClasses]))\n",
    "    \n",
    "    def gaussian(self, x, mean, std):\n",
    "        if(std==0):\n",
    "            return 1\n",
    "        return np.log(1/(std*np.sqrt(2*np.pi)))*pow(np.e,-(0.5*pow((x-mean)/std, 2)))\n",
    "    \n",
    "    def laplace(self, n, N, k=len(columnValueType[0]),alpha = 0.0001):\n",
    "        return (n+alpha)/(N+(alpha*k))\n",
    "\n",
    "    def fit(self, train_x:pd.DataFrame, train_y:pd.Series):\n",
    "        for i in self.targetClasses:\n",
    "            subset = train_x.loc[train_y[train_y==i].index]\n",
    "            self.targetClasses[i] = {\n",
    "                \"p(y)\":len(subset)/len(train_x),\n",
    "                \"p(X)\": dict(),\n",
    "                \"gaussian\": dict(),\n",
    "                \"length\": len(subset)}\n",
    "            for j in train_x.columns:\n",
    "                if subset[j].name in columnValueType[1]:\n",
    "                    mean = subset[j].mean()\n",
    "                    std = subset[j].std()\n",
    "                    self.targetClasses[i]['gaussian'].update({j:{\n",
    "                        'mean': mean, \n",
    "                        'std': std}})\n",
    "                        \n",
    "                else:\n",
    "                    self.targetClasses[i]['p(X)'][j] = dict()\n",
    "                    for k in train_x[j].unique():\n",
    "                        if(k in subset[j].unique()):\n",
    "                            self.targetClasses[i]['p(X)'][j].update({\n",
    "                                k:self.laplace(len(subset[subset[j]==k]),len(subset))})\n",
    "                        else:\n",
    "                            self.targetClasses[i]['p(X)'][j].update({\n",
    "                                k:self.laplace(0,len(subset))})\n",
    "        return self\n",
    "\n",
    "    def predict(self, test_x:pd.DataFrame):\n",
    "        predictClassTemplate = dict(zip(self.targetClasses, [None]*len(self.targetClasses)))\n",
    "        predictClasses = dict()\n",
    "        for i in predictClassTemplate:\n",
    "            predictClassTemplate[i] = np.log(self.targetClasses[i]['p(y)'])\n",
    "\n",
    "        def columnPredictor(columnValue, columnName, predictRowClass):\n",
    "            for i in predictRowClass:\n",
    "                if(columnName in columnValueType[0]):\n",
    "                    if columnName in self.targetClasses[i]['p(X)']:\n",
    "                        probability = self.targetClasses[i]['p(X)'][columnName][columnValue]\n",
    "                    else:\n",
    "                        probability = self.laplace(0,self.targetClasses[i]['length'])\n",
    "                    np.log(probability)\n",
    "                else:    \n",
    "                    mean = self.targetClasses[i]['gaussian'][columnName]['mean']\n",
    "                    std =  self.targetClasses[i]['gaussian'][columnName]['std']\n",
    "                    probability = self.gaussian(columnValue, mean, std)\n",
    "                predictRowClass[i]+=probability\n",
    "\n",
    "        def rowPredictor(row):\n",
    "            rowProbability = None\n",
    "            predictRowClass = predictClassTemplate.copy()\n",
    "            for i in row.index:\n",
    "                columnPredictor(row[i],i,predictRowClass)\n",
    "            return predictRowClass\n",
    "        \n",
    "        return test_x.apply(rowPredictor,axis=1)\n",
    "\n",
    "nb = NaiveBayes(df[TARGETCOLUMN].unique()).fit(train_x, train_y)\n",
    "predictedProbabilities = nb.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<span>\n",
    "    <h5>The cell below: </h5>\n",
    "    <ul>\n",
    "        <li>Creates a function dictMax which returns the key of the maximum value present in a dictionary</li>\n",
    "        <br>\n",
    "        <li>Calculates the accuracy of the predicted values</li>\n",
    "    </ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923675350349844"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dictMax(x:dict):\n",
    "    keyList = list(x.keys())\n",
    "    valueList = list(x.values())\n",
    "    maxVal, maxInd = 0, 0\n",
    "    for i in range(len(x)):\n",
    "        maxInd, maxVal = (maxInd, maxVal) \\\n",
    "            if (maxVal>valueList[i]) and (i!=0) \\\n",
    "                else (i, valueList[i])\n",
    "    return keyList[maxInd]\n",
    "\n",
    "sum(pd.concat({'predict':predictedProbabilities\\\n",
    "    .apply(dictMax), 'actual':test_y}, axis=1)\\\n",
    "        .apply(lambda x: 1 if x['predict']==x['actual'] else 0, axis=1))/len(test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52753ccbbeb19d3563e99f445e87e827e013afbba741a1ef9aaa60ef3b3e479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
