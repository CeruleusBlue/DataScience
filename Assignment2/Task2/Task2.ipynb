{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below: </h5>\n",
    "    <ul>\n",
    "        <li>Reads the data from the file onto a spark dataframes</li>\n",
    "        <br>\n",
    "        <li>Separates the uris and hyperlinks(dropping the rdf prefixes) into two dataframes</li>\n",
    "        <br>\n",
    "        <li>Creates views for the dataframes so that sql queries can be performed on them</li>\n",
    "    </ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/27 02:15:39 WARN Utils: Your hostname, MSI resolves to a loopback address: 127.0.1.1; using 172.23.129.232 instead (on interface eth0)\n",
      "22/10/27 02:15:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/27 02:15:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/27 02:15:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/27 02:15:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import pyspark, pyspark.sql, numpy as np\n",
    "\n",
    "spark:pyspark.sql.SparkSession = pyspark.sql.SparkSession.Builder().getOrCreate()\n",
    "\n",
    "df = spark.read.csv('Task2/gr0.California', sep=\" \")\n",
    "uri = df.filter(\"_c0 = 'n'\").drop('_c0')\n",
    "hyperlink = df.filter(\"_c0 = 'e'\").drop('_c0')\n",
    "uri.createGlobalTempView('uri')\n",
    "hyperlink.createGlobalTempView('hyperlink')\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below: </h5>\n",
    "    <li>Runs an sql query that returns all uris and the out-degree for rows which contain the maximum out-degree</li>\n",
    "    <br>\n",
    "    <li>This has been done using nested select queries and joins</li>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+\n",
      "|url                                       |count|\n",
      "+------------------------------------------+-----+\n",
      "|http://www.water.ca.gov/www.gov.sites.html|164  |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxOut = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT global_temp.uri._c2 AS url, count\n",
    "    FROM(\n",
    "        SELECT _c1, count(_c1) AS count\n",
    "        FROM global_temp.hyperlink\n",
    "        GROUP BY _c1\n",
    "        ) T1\n",
    "    RIGHT JOIN(\n",
    "        SELECT max(count) as maxCount\n",
    "        FROM(\n",
    "            SELECT _c1, count(_c1) AS count\n",
    "            FROM global_temp.hyperlink\n",
    "            GROUP BY _c1\n",
    "            ) T1\n",
    "        )T2\n",
    "    ON count = maxCount\n",
    "    LEFT JOIN global_temp.uri\n",
    "    ON T1._c1 = global_temp.uri._c1\n",
    "    \"\"\"\n",
    ")\n",
    "maxOut.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(0, 162, 255)\">\n",
    "    The query above outputs only one row which contains \n",
    "    the URI for the website and the out-degree.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below: </h5>\n",
    "    <li>Runs an sql query that returns all uris and the in-degree for rows which contain the maximum in-degree</li>\n",
    "    <br>\n",
    "    <li>This has been done using nested select queries and joins</li>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|url                  |count|\n",
      "+---------------------+-----+\n",
      "|http://www.yahoo.com/|199  |\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxIn = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT global_temp.uri._c2 AS url, count\n",
    "    FROM(\n",
    "        SELECT _c2, count(_c2) AS count\n",
    "        FROM global_temp.hyperlink\n",
    "        GROUP BY _c2\n",
    "        ) T1\n",
    "    RIGHT JOIN(\n",
    "        SELECT max(count) as maxCount\n",
    "        FROM(\n",
    "            SELECT _c2, count(_c2) AS count\n",
    "            FROM global_temp.hyperlink\n",
    "            GROUP BY _c2\n",
    "            ) T1\n",
    "        )T2\n",
    "    ON count = maxCount\n",
    "    LEFT JOIN global_temp.uri\n",
    "    ON T1._c2 = global_temp.uri._c1\n",
    "    \"\"\"\n",
    ")\n",
    "maxIn.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(0, 162, 255)\">\n",
    "    The query above outputs only one row which contains \n",
    "    the URI for the website and the in-degree.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below: </h5>\n",
    "    <li>Runs an sql query to calculate the average out-degree</li>\n",
    "    <br>\n",
    "    <li>This has been done using a nested select query</li>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|outAverage       |\n",
      "+-----------------+\n",
      "|3.212651680923016|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meanOut = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT avg(count) AS outAverage\n",
    "    FROM(\n",
    "        SELECT _c1, count(_c1) AS count\n",
    "        FROM global_temp.hyperlink\n",
    "        GROUP BY _c1\n",
    "        ) T1\n",
    "    \"\"\"\n",
    ")\n",
    "meanOut.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(0, 162, 255)\">\n",
    "    The query above outputs only one row which contains \n",
    "    the average out-degree value.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below: </h5>\n",
    "    <li>Runs an sql query to calculate the average in-degree</li>\n",
    "    <br>\n",
    "    <li>This has been done using a nested select query</li>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|inAverage        |\n",
      "+-----------------+\n",
      "|7.694140066698428|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meanIn = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT avg(count) AS inAverage\n",
    "    FROM(\n",
    "        SELECT _c2, count(_c2) AS count\n",
    "        FROM global_temp.hyperlink\n",
    "        GROUP BY _c2\n",
    "        ) T1\n",
    "    \"\"\"\n",
    ")\n",
    "meanIn.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(0, 162, 255)\">\n",
    "    The query above outputs only one row which contains \n",
    "    the average in-degree value.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "    <h5>The cell below: </h5>\n",
    "    <li>Runs an sql query to return the count of rows which has an out-degree of 0</li>\n",
    "    <br>\n",
    "    <li>This has been done using a nested select query.</li>\n",
    "    <br>\n",
    "    <li>The query is based on the fact that if the uri doesn't have any out hyperlink entries \n",
    "        then the out-degree of the uri is 0.</li>\n",
    "    <br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|webpageCount|\n",
      "+------------+\n",
      "|4637        |\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zeroOut = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT count(_c1) AS webpageCount\n",
    "    FROM global_temp.uri\n",
    "    WHERE _c1 NOT IN(\n",
    "        SELECT DISTINCT _c1\n",
    "        FROM global_temp.hyperlink\n",
    "    )\n",
    "    \"\"\"\n",
    ")\n",
    "zeroOut.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(0, 162, 255)\">\n",
    "    The query above outputs only one row which contains \n",
    "    the count of the uris with zero out-degree.\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52753ccbbeb19d3563e99f445e87e827e013afbba741a1ef9aaa60ef3b3e479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
